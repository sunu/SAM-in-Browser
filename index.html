<!DOCTYPE html>
<html>
<header>
    <title>Segment Anything Frontend Only Demo</title>
</header>

<body>
    <h1>Segement Anything in the Browser</h1>
    <div>
        <input title="Image from File" type="file" id="file-in" name="file-in">
    </div>
    <div style="display: none;">
        <img id="original-image" src="#" />
    </div>
    <h3>Status</h3>
    <span id="status">No image uploaded</span>
    <h3>Resized Image and Mask</h3>
    <canvas id="canvas"></canvas>
    <!-- import ONNXRuntime Web from CDN -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"> </script>
    <script>
        var canvas = document.getElementById('canvas');
        const dimension = 1024;
        var image_embeddings;
        var imageImageData

        async function handleClick(event) {
            const rect = canvas.getBoundingClientRect();
            const x = event.clientX - rect.left;
            const y = event.clientY - rect.top;
            
            console.log('Clicked position:', x, y);
            document.getElementById("status").textContent = `Clicked on (${x}, ${y}). Downloading the decoder model if needed and generating mask...`;

            let context = canvas.getContext('2d');
            context.clearRect(0, 0, canvas.width, canvas.height);
            canvas.width = imageImageData.width;
            canvas.height = imageImageData.height;
            context.putImageData(imageImageData, 0, 0);
            context.fillStyle = 'green';
            context.fillRect(x, y, 10, 10);

            const pointCoords = new ort.Tensor(new Float32Array([x, y, 0, 0]), [1, 2, 2]);
            const pointLabels = new ort.Tensor(new Float32Array([0, -1]), [1, 2]);
            // generate a (1, 1, 256, 256) tensor with all values set to 0
            const maskInput = new ort.Tensor(new Float32Array(256 * 256), [1, 1, 256, 256]);
            const hasMask = new ort.Tensor(new Float32Array([0]), [1,]);
            const origianlImageSize = new ort.Tensor(new Float32Array([684, 1024]), [2,]);

            const decodingSession = await ort.InferenceSession.create('./models/sam_vit_b_01ec64.decoder.onnx');
            console.log("Decoder session", decodingSession);
            const decodingFeeds = {
                "image_embeddings": image_embeddings,
                "point_coords": pointCoords,
                "point_labels": pointLabels,
                "mask_input": maskInput,
                "has_mask_input": hasMask,
                "orig_im_size": origianlImageSize
            }
            console.log("generating mask...");
            start = Date.now();
            try {
                results = await decodingSession.run(decodingFeeds);
                console.log("Generated mask:", results);
                const mask = results.masks;
                const maskImageData = mask.toImageData();
                context.globalAlpha = 0.5;
                // convert image data to image bitmap
                let imageBitmap = await createImageBitmap(maskImageData);
                context.drawImage(imageBitmap, 0, 0);

            } catch (error) {
                console.log(`caught error: ${error}`)
            }
            end = Date.now();
            console.log(`generating masks took ${(end - start)/1000} seconds`);
            document.getElementById("status").textContent = `Mask generated. Click on the image to generate new mask.`;
        }

        async function handleImage(img) {
            console.log(status);
            document.getElementById("status").textContent = `Uploaded image of size ${img.width}x${img.height}. Downloading the encoder model (~100 MB) if not cached and generating embedding. this will take a minute...`;
            console.log(`Uploaded image of size ${img.width}x${img.height}`);
            const scaleX = dimension / img.width;
            const scaleY = dimension / img.height;

            const resizedTensor = await ort.Tensor.fromImage(img, options = { resizedWidth: 1024, resizedHeight: 684 });
            const resizeImage = resizedTensor.toImageData();
            let imageDataTensor = await ort.Tensor.fromImage(resizeImage);
            imageImageData = imageDataTensor.toImageData();
            console.log("image data tensor:", imageDataTensor);

            // Presenting the images on dom
            canvas.width = imageImageData.width;
            canvas.height = imageImageData.height;
            let context = canvas.getContext('2d');
            context.putImageData(imageImageData, 0, 0);
            
            let tf_tensor = tf.tensor(imageDataTensor.data, imageDataTensor.dims);
            tf_tensor = tf_tensor.reshape([3, 684, 1024]);
            tf_tensor = tf_tensor.transpose([1, 2, 0]).mul(255);
            imageDataTensor = new ort.Tensor(tf_tensor.dataSync(), tf_tensor.shape);

            const session = await ort.InferenceSession.create('https://files.sunu.in/sam_vit_b_01ec64.encoder.preprocess.quant.onnx');
            console.log("Encoder Session", session);
            const feeds = { "input_image": imageDataTensor }
            console.log("Computing image embedding; this will take a minute...")
            let start = Date.now();
            let results;
            try {
                results = await session.run(feeds);
                console.log("Encoding result:", results);
                image_embeddings = results.image_embeddings;
            } catch (error) {
                console.log(`caught error: ${error}`)
                document.getElementById("status").textContent = `Error: ${error}`;
            }
            let end = Date.now();
            let time_taken = (end - start) / 1000;
            console.log(`Computing image embedding took ${time_taken} seconds`);
            document.getElementById("status").textContent = `Embedding generated in ${time_taken} seconds. Click on the image to generate mask.`;

            canvas.addEventListener('click', handleClick);

        }


        function loadImage(fileReader) {
            var img = document.getElementById("original-image");
            img.onload = () => handleImage(img);
            img.src = fileReader.result;
        }

        // use an async context to call onnxruntime functions.
        async function main() {
            var img = document.getElementById("original-image");
            document.getElementById("file-in").onchange = function (evt) {
                let target = evt.target || window.event.src, files = target.files;
                if (FileReader && files && files.length) {
                    var fileReader = new FileReader();
                    fileReader.onload = () => loadImage(fileReader);
                    fileReader.readAsDataURL(files[0]);
                }
            };
        }

        main();
    </script>
</body>

</html>